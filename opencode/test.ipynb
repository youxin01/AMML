{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "15089827",
   "metadata": {},
   "source": [
    "有代码运行环境，那么我可以直接用以下流程：\n",
    "增加一个字典，使用导入写\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc9b0141",
   "metadata": {},
   "source": [
    "# 开源代码"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b53e79e",
   "metadata": {},
   "source": [
    "### 第一步planner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3ca4f1ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from planner.tools import get_pla_user\n",
    "from planner.prompt import get_planer\n",
    "from utils.api import gpt_chat\n",
    "type1=\"opt\"\n",
    "question=\"./test_case/o4/question.txt\"\n",
    "\n",
    "planer = get_planer(problem_type=type1)\n",
    "info = get_pla_user(ques=question,problem_type=type1)\n",
    "\n",
    "# response1 = gpt_chat(sys=planer,user=info,provider=\"deepseek\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1c760228",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_file(file_path: str, content):\n",
    "    \"\"\"\n",
    "    Write content to a file based on its extension.\n",
    "    \n",
    "    Args:\n",
    "        file_path: Path to the file to be written\n",
    "        content: Content to write (string for txt/md, list of strings for csv)\n",
    "    \"\"\"\n",
    "    if file_path.endswith('txt'):\n",
    "        with open(file_path, 'w', encoding='utf-8') as f:\n",
    "            f.write(content if isinstance(content, str) else '\\n'.join(content))\n",
    "    elif file_path.endswith('csv'):\n",
    "        with open(file_path, 'w', encoding='utf-8', newline='') as f:\n",
    "            if isinstance(content, list):\n",
    "                f.writelines(content)\n",
    "            else:\n",
    "                f.write(content)\n",
    "    elif file_path.endswith('md'):\n",
    "        with open(file_path, 'w', encoding='utf-8') as f:\n",
    "            f.write(content if isinstance(content, str) else '\\n'.join(content))\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported file format\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "56c38b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取文件内容\n",
    "def read_file(file_path: str):\n",
    "    \"\"\"\n",
    "    Read the content of a file and return it as a string.\n",
    "    \"\"\"\n",
    "    if file_path.endswith('txt'):\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            return f.read()\n",
    "    if file_path.endswith('csv'):\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            return f.readlines()\n",
    "    if file_path.endswith('md'):\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            return f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c6dcc53",
   "metadata": {},
   "source": [
    "## 匹配函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7c00e402",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 已存储: statistic.md (包含 2 个工具块)\n",
      "✅ 已存储: data_clean.md (包含 5 个工具块)\n",
      "✅ 已存储: graph_optimization.md (包含 5 个工具块)\n",
      "✅ 已存储: machine_learning.md (包含 15 个工具块)\n",
      "✅ 已存储: math_optimization.md (包含 10 个工具块)\n",
      "✅ 已存储: feature_process.md (包含 7 个工具块)\n",
      "✅ 已存储: evaluate_model.md (包含 3 个工具块)\n"
     ]
    }
   ],
   "source": [
    "from planner.tools import get_plan\n",
    "from utils.rag import ChoromaDBManager\n",
    "\n",
    "\n",
    "chroma_db = ChoromaDBManager(\"./test_case/o4/tool_db\")\n",
    "chroma_db.store_tools_to_db(dir_path=\"./tool_doc_md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "75ede46f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plan = get_plan(str_path=\"./test_case/o4/plan_deepseek.txt\")\n",
    "funcs=chroma_db.get_all_tools(plan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "48ef4587",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'tool_name': 'solve_lp',\n",
       "  'content': '**Name:** solve_lp  \\n**Description:** 用于简单线性规划问题，线性规划求解函数。\\n**Applicable Situations:**  \\n- 需要求解目标函数最小化的线性规划问题  \\n\\n**Parameters:**  \\n- `c`:  \\n  - \\u200b**Type:** `array-like`  \\n  - \\u200b**Description:** 目标函数系数向量，维度需与变量数一致  \\n\\n- `A_ub`:  \\n  - \\u200b**Type:** `2D array-like | None`  \\n  - \\u200b**Description:** 不等式约束系数矩阵（默认None），每行对应一个约束条件  \\n\\n- `b_ub`:  \\n  - \\u200b**Type:** `array-like | None`  \\n  - \\u200b**Description:** 不等式约束右侧常数向量（默认None）  \\n\\n- `A_eq`:  \\n  - \\u200b**Type:** `2D array-like | None`  \\n  - \\u200b**Description:** 等式约束系数矩阵（默认None）  \\n\\n- `b_eq`:  \\n  - \\u200b**Type:** `array-like | None`  \\n  - \\u200b**Description:** 等式约束右侧常数向量（默认None）  \\n\\n- `bounds`:  \\n  - \\u200b**Type:** `list of tuples | None`  \\n  - \\u200b**Description:** 变量边界列表（默认None），每个元组表示变量下界和上界  \\n  - \\u200b**Example:** `[(0, None), (0, 5)]` 表示x₁≥0，x₂∈[0,5]  \\n\\n**Result:**  \\n- 成功时返回包含最优解x和最优值fun的元组  \\n- 失败时返回包含错误信息的字符串  \\n\\n**Example Call:**  \\n```python\\n# 求解 min -x1 + 4x2 \\n# s.t.  x1 + x2 <= 5\\n#       2x1 + x2 = 4\\n#       x1 ∈ [0,3], x2 ≥ 0\\nx_opt, f_opt = solve_lp(\\n    c=[-1, 4],\\n    A_ub=[[1, 1]],\\n    b_ub=[5],\\n    A_eq=[[2, 1]],\\n    b_eq=[4],\\n    bounds=[(0, 3), (0, None)]\\n)\\n```',\n",
       "  'source_file': 'math_optimization.md',\n",
       "  'distance': 0.5363641381263733}]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "funcs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7ff00fd",
   "metadata": {},
   "source": [
    "## Developer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5a0102ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from developer.prompt import get_developer\n",
    "from developer.tools import get_dev_user\n",
    "funcs = [{'tool_name': 'solve_lp',\n",
    "  'content': '**Name:** solve_lp  \\n**Description:** 用于简单线性规划问题，线性规划求解函数。\\n**Applicable Situations:**  \\n- 需要求解目标函数最小化的线性规划问题  \\n\\n**Parameters:**  \\n- `c`:  \\n  - \\u200b**Type:** `array-like`  \\n  - \\u200b**Description:** 目标函数系数向量，维度需与变量数一致  \\n\\n- `A_ub`:  \\n  - \\u200b**Type:** `2D array-like | None`  \\n  - \\u200b**Description:** 不等式约束系数矩阵（默认None），每行对应一个约束条件  \\n\\n- `b_ub`:  \\n  - \\u200b**Type:** `array-like | None`  \\n  - \\u200b**Description:** 不等式约束右侧常数向量（默认None）  \\n\\n- `A_eq`:  \\n  - \\u200b**Type:** `2D array-like | None`  \\n  - \\u200b**Description:** 等式约束系数矩阵（默认None）  \\n\\n- `b_eq`:  \\n  - \\u200b**Type:** `array-like | None`  \\n  - \\u200b**Description:** 等式约束右侧常数向量（默认None）  \\n\\n- `bounds`:  \\n  - \\u200b**Type:** `list of tuples | None`  \\n  - \\u200b**Description:** 变量边界列表（默认None），每个元组表示变量下界和上界  \\n  - \\u200b**Example:** `[(0, None), (0, 5)]` 表示x₁≥0，x₂∈[0,5]  \\n\\n**Result:**  \\n- 成功时返回包含最优解x和最优值fun的元组  \\n- 失败时返回包含错误信息的字符串  \\n\\n**Example Call:**  \\n```python\\n# 求解 min -x1 + 4x2 \\n# s.t.  x1 + x2 <= 5\\n#       2x1 + x2 = 4\\n#       x1 ∈ [0,3], x2 ≥ 0\\nx_opt, f_opt = solve_lp(\\n    c=[-1, 4],\\n    A_ub=[[1, 1]],\\n    b_ub=[5],\\n    A_eq=[[2, 1]],\\n    b_eq=[4],\\n    bounds=[(0, 3), (0, None)]\\n)\\n```',\n",
    "  'source_file': 'math_optimization.md',\n",
    "  'distance': 0.5363641381263733}]\n",
    "devloper_prompt = get_developer(problem_type=type1,func=funcs)\n",
    "user2 = get_dev_user(question=question,problem_type=type1)\n",
    "\n",
    "# response2 = gpt_chat(sys=devloper_prompt,user=user2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21679bcb",
   "metadata": {},
   "source": [
    "## 编译"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "abb98682",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.notebook_serializer import NotebookSerializer\n",
    "from utils.local_interpreter import LocalCodeInterpreter\n",
    "import sys\n",
    "import json\n",
    "import os\n",
    "dirname = \"./\"\n",
    "notebook = NotebookSerializer(dirname)\n",
    "\n",
    "# agents code执行\n",
    "code_interpreter = LocalCodeInterpreter(work_dir=dirname,notebook_serializer=notebook,task_id=\"111\")\n",
    "code_interpreter.initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1739d293",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "\n",
    "for func in funcs:\n",
    "    file = set()\n",
    "    if func[\"source_file\"] not in file:\n",
    "        module_name = f\"tool_code.{func['source_file'].replace('.md', '')}\"\n",
    "        module = importlib.import_module(module_name)\n",
    "        header = module.get_header()\n",
    "        tool = f\"from tool_code.{func['source_file'].replace('.md', '')} import {func['tool_name']}\"\n",
    "        code_interpreter.execute_code(header)\n",
    "        code_interpreter.execute_code(tool)\n",
    "        file.add(func['source_file'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "98c16f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.utils1 import extract_functions\n",
    "\n",
    "functions = extract_functions(\"./test_case/o4/dev_deepseek.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b4c8303e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "def convert_str_function(json_str):\n",
    "    data = ast.literal_eval(json_str)\n",
    "    results = []\n",
    "    for item in data:\n",
    "        name = item['name']\n",
    "        args = item['args']\n",
    "        arg_strs = []\n",
    "        for k, v in args.items():\n",
    "            # 保证字典等非字符串不被误转义为字符串\n",
    "            if isinstance(v, str):\n",
    "                arg_strs.append(f'{k}=\"{v}\"')\n",
    "            else:\n",
    "                arg_strs.append(f\"{k}={v}\")\n",
    "        arg_str = \", \".join(arg_strs)\n",
    "        call_str = f'result = {name}({arg_str})'\n",
    "        results.append(call_str)\n",
    "\n",
    "    return \"\\n\".join(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27044919",
   "metadata": {},
   "source": [
    "### 两步"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "894b82ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "func_call = convert_str_function(functions[0])\n",
    "data_processed = func_call.split(\"\\n\")\n",
    "updated_lines = []\n",
    "\n",
    "train = 0\n",
    "test = 0\n",
    "\n",
    "for tmp in data_processed:\n",
    "    if 'data=\"train_data\"' in tmp:\n",
    "        if train == 0:\n",
    "            data_name = 'train_data'\n",
    "        else:\n",
    "            data_name = f'train_data{train}'\n",
    "        output_var = f'train_data{train + 1}'\n",
    "        tmp = tmp.replace('data=\"train_data\"', f'data={data_name}')\n",
    "        tmp = re.sub(r'^result\\s*=', f'{output_var} =', tmp)\n",
    "        train += 1\n",
    "    elif 'data=\"test_data\"' in tmp:\n",
    "        if test == 0:\n",
    "            data_name = 'test_data'\n",
    "        else:\n",
    "            data_name = f'test_data{test}'\n",
    "        output_var = f'test_data{test + 1}'\n",
    "        tmp = tmp.replace('data=\"test_data\"', f'data={data_name}')\n",
    "        tmp = re.sub(r'^result\\s*=', f'{output_var} =', tmp)\n",
    "        test += 1\n",
    "    updated_lines.append(tmp)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ee9ded99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['train_data1 = fill_missing_values(data=train_data, columns=[\\'HomePlanet\\', \\'CryoSleep\\', \\'Destination\\', \\'Age\\', \\'VIP\\', \\'RoomService\\', \\'FoodCourt\\', \\'ShoppingMall\\', \\'Spa\\', \\'VRDeck\\'], strategy=\"mode\")',\n",
       " 'test_data1 = fill_missing_values(data=test_data, columns=[\\'HomePlanet\\', \\'CryoSleep\\', \\'Destination\\', \\'Age\\', \\'VIP\\', \\'RoomService\\', \\'FoodCourt\\', \\'ShoppingMall\\', \\'Spa\\', \\'VRDeck\\'], strategy=\"mode\")',\n",
       " 'train_data2 = detect_and_handle_outliers_zscore(data=train_data1, columns=[\\'Age\\', \\'RoomService\\', \\'FoodCourt\\', \\'ShoppingMall\\', \\'Spa\\', \\'VRDeck\\'], threshold=3.0, method=\"clip\")',\n",
       " 'test_data2 = detect_and_handle_outliers_zscore(data=test_data1, columns=[\\'Age\\', \\'RoomService\\', \\'FoodCourt\\', \\'ShoppingMall\\', \\'Spa\\', \\'VRDeck\\'], threshold=3.0, method=\"clip\")',\n",
       " \"train_data3 = one_hot_encode(data=train_data2, columns=['HomePlanet', 'CryoSleep', 'Destination', 'VIP'])\",\n",
       " \"test_data3 = one_hot_encode(data=test_data2, columns=['HomePlanet', 'CryoSleep', 'Destination', 'VIP'])\",\n",
       " \"train_data4 = label_encode(data=train_data3, columns=['Transported'])\"]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "updated_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f1e42ca4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('', False, '')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_load =\"\"\"train_data = pd.read_csv(\"{train_path}\")\n",
    "test_data = pd.read_csv(\"{test_path}\")\"\"\"\n",
    "path1 = \"./test_case/p1/train.csv\"\n",
    "path2 = \"./test_case/p1/test.csv\"\n",
    "data_load=data_load.format(train_path=path1,test_path=path2)\n",
    "\n",
    "code_interpreter.execute_code(data_load)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "92ad4b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in updated_lines:\n",
    "    code_interpreter.execute_code(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "72611400",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = convert_str_function(functions[1])\n",
    "model1=model.replace('\"train_data\"', f'train_data{train}').replace('\"test_data\"', f'test_data{test}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4ca6bf69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('---------------------------------------------------------------------------\\nKeyError                                  Traceback (most recent call last)\\nFile ~/anaconda3/envs/base1/lib/python3.10/site-packages/xgboost/data.py:407, in pandas_feature_info(data, meta, feature_names, feature_types, enable_categorical)\\n    406 try:\\n--> 407     new_feature_types.append(_pandas_dtype_mapper[dtype.name])\\n    408 except KeyError:\\n\\nKeyError: \\'object\\'\\n\\nDuring handling of the above exception, another excepti\\n... (内容已截断) ...\\n3.10/site-packages/xgboost/data.py:372, in _invalid_dataframe_dtype(data)\\n    370 type_err = \"DataFrame.dtypes for data must be int, float, bool or category.\"\\n    371 msg = f\"\"\"{type_err} {_ENABLE_CAT_ERR} {err}\"\"\"\\n--> 372 raise ValueError(msg)\\n\\nValueError: DataFrame.dtypes for data must be int, float, bool or category. When categorical type is supplied, the experimental DMatrix parameter`enable_categorical` must be set to `True`.  Invalid columns:PassengerId: object, Cabin: object, Name: object',\n",
       " True,\n",
       " '---------------------------------------------------------------------------\\nKeyError                                  Traceback (most recent call last)\\nFile ~/anaconda3/envs/base1/lib/python3.10/site-packages/xgboost/data.py:407, in pandas_feature_info(data, meta, feature_names, feature_types, enable_categorical)\\n    406 try:\\n--> 407     new_feature_types.append(_pandas_dtype_mapper[dtype.name])\\n    408 except KeyError:\\n\\nKeyError: \\'object\\'\\n\\nDuring handling of the above exception, another excepti\\n... (内容已截断) ...\\n3.10/site-packages/xgboost/data.py:372, in _invalid_dataframe_dtype(data)\\n    370 type_err = \"DataFrame.dtypes for data must be int, float, bool or category.\"\\n    371 msg = f\"\"\"{type_err} {_ENABLE_CAT_ERR} {err}\"\"\"\\n--> 372 raise ValueError(msg)\\n\\nValueError: DataFrame.dtypes for data must be int, float, bool or category. When categorical type is supplied, the experimental DMatrix parameter`enable_categorical` must be set to `True`.  Invalid columns:PassengerId: object, Cabin: object, Name: object')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "code_interpreter.execute_code(model1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4122ee19",
   "metadata": {},
   "source": [
    "### 单步"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "261707ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[    {        \"name\": \"solve_lp\",        \"args\": {            \"c\": [-500, -550, -630, -1000, -800, -700, -800, -700, -600, -950, -900, -930, -1000, -960, -840, -650, -600, -700, -1200, -1040, -980, -860, -880, -780],            \"A_ub\": [                [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],                [0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],                [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0],                [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1],                [1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0],                [0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0],                [0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0],                [0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0],                [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0],                [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1]            ],            \"b_ub\": [76, 40, 96, 40, 42, 56, 44, 39, 60, 59],            \"A_eq\": None,            \"b_eq\": None,            \"bounds\": [(0, None)]*24        }    }]'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "functions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d8fa228d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "malformed node or string on line 1: <ast.BinOp object at 0x7f74b7851360>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[38], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mconvert_str_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m model\n",
      "File \u001b[0;32m~/A-Projects/Graduation/embedding/opencode/utils/utils1.py:81\u001b[0m, in \u001b[0;36mconvert_str_function\u001b[0;34m(json_str)\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mconvert_str_function\u001b[39m(json_str):\n\u001b[0;32m---> 81\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mast\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mliteral_eval\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjson_str\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     82\u001b[0m     results \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     83\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m data:\n",
      "File \u001b[0;32m~/anaconda3/envs/base1/lib/python3.10/ast.py:108\u001b[0m, in \u001b[0;36mliteral_eval\u001b[0;34m(node_or_string)\u001b[0m\n\u001b[1;32m    106\u001b[0m                 \u001b[38;5;28;01mreturn\u001b[39;00m left \u001b[38;5;241m-\u001b[39m right\n\u001b[1;32m    107\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _convert_signed_num(node)\n\u001b[0;32m--> 108\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_convert\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode_or_string\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/base1/lib/python3.10/ast.py:88\u001b[0m, in \u001b[0;36mliteral_eval.<locals>._convert\u001b[0;34m(node)\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(\u001b[38;5;28mmap\u001b[39m(_convert, node\u001b[38;5;241m.\u001b[39melts))\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(node, List):\n\u001b[0;32m---> 88\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m_convert\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43melts\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(node, Set):\n\u001b[1;32m     90\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mset\u001b[39m(\u001b[38;5;28mmap\u001b[39m(_convert, node\u001b[38;5;241m.\u001b[39melts))\n",
      "File \u001b[0;32m~/anaconda3/envs/base1/lib/python3.10/ast.py:97\u001b[0m, in \u001b[0;36mliteral_eval.<locals>._convert\u001b[0;34m(node)\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(node\u001b[38;5;241m.\u001b[39mkeys) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(node\u001b[38;5;241m.\u001b[39mvalues):\n\u001b[1;32m     96\u001b[0m         _raise_malformed_node(node)\n\u001b[0;32m---> 97\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m_convert\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeys\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     98\u001b[0m \u001b[43m                    \u001b[49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m_convert\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(node, BinOp) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(node\u001b[38;5;241m.\u001b[39mop, (Add, Sub)):\n\u001b[1;32m    100\u001b[0m     left \u001b[38;5;241m=\u001b[39m _convert_signed_num(node\u001b[38;5;241m.\u001b[39mleft)\n",
      "File \u001b[0;32m~/anaconda3/envs/base1/lib/python3.10/ast.py:97\u001b[0m, in \u001b[0;36mliteral_eval.<locals>._convert\u001b[0;34m(node)\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(node\u001b[38;5;241m.\u001b[39mkeys) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(node\u001b[38;5;241m.\u001b[39mvalues):\n\u001b[1;32m     96\u001b[0m         _raise_malformed_node(node)\n\u001b[0;32m---> 97\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m_convert\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeys\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     98\u001b[0m \u001b[43m                    \u001b[49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m_convert\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(node, BinOp) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(node\u001b[38;5;241m.\u001b[39mop, (Add, Sub)):\n\u001b[1;32m    100\u001b[0m     left \u001b[38;5;241m=\u001b[39m _convert_signed_num(node\u001b[38;5;241m.\u001b[39mleft)\n",
      "File \u001b[0;32m~/anaconda3/envs/base1/lib/python3.10/ast.py:107\u001b[0m, in \u001b[0;36mliteral_eval.<locals>._convert\u001b[0;34m(node)\u001b[0m\n\u001b[1;32m    105\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    106\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m left \u001b[38;5;241m-\u001b[39m right\n\u001b[0;32m--> 107\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_convert_signed_num\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/base1/lib/python3.10/ast.py:81\u001b[0m, in \u001b[0;36mliteral_eval.<locals>._convert_signed_num\u001b[0;34m(node)\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     80\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m-\u001b[39m operand\n\u001b[0;32m---> 81\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_convert_num\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/base1/lib/python3.10/ast.py:72\u001b[0m, in \u001b[0;36mliteral_eval.<locals>._convert_num\u001b[0;34m(node)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_convert_num\u001b[39m(node):\n\u001b[1;32m     71\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(node, Constant) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(node\u001b[38;5;241m.\u001b[39mvalue) \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mcomplex\u001b[39m):\n\u001b[0;32m---> 72\u001b[0m         \u001b[43m_raise_malformed_node\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     73\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m node\u001b[38;5;241m.\u001b[39mvalue\n",
      "File \u001b[0;32m~/anaconda3/envs/base1/lib/python3.10/ast.py:69\u001b[0m, in \u001b[0;36mliteral_eval.<locals>._raise_malformed_node\u001b[0;34m(node)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m lno \u001b[38;5;241m:=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(node, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlineno\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m     68\u001b[0m     msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m on line \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlno\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m---> 69\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg \u001b[38;5;241m+\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnode\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: malformed node or string on line 1: <ast.BinOp object at 0x7f74b7851360>"
     ]
    }
   ],
   "source": [
    "model = convert_str_function(functions[0])\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2c0e771f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('', False, '')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "code_interpreter.execute_code(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d522dd81",
   "metadata": {},
   "source": [
    "## 汇总"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a7f25e8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "planner start\n",
      "RAG start\n",
      "✅ 已存储: statistic.md (包含 2 个工具块)\n",
      "✅ 已存储: data_clean.md (包含 5 个工具块)\n",
      "✅ 已存储: graph_optimization.md (包含 5 个工具块)\n",
      "✅ 已存储: machine_learning.md (包含 15 个工具块)\n",
      "✅ 已存储: math_optimization.md (包含 10 个工具块)\n",
      "✅ 已存储: feature_process.md (包含 7 个工具块)\n",
      "✅ 已存储: evaluate_model.md (包含 3 个工具块)\n",
      "developer start\n",
      "code execute start\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "malformed node or string on line 1: <ast.BinOp object at 0x7f76d8167880>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 112\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcode execute start\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    111\u001b[0m exec_func \u001b[38;5;241m=\u001b[39m extract_functions(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mdirname(question),\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdev_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00magent\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m--> 112\u001b[0m \u001b[43mcode_exe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprepare\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepare_funcs\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtype1\u001b[49m\u001b[43m,\u001b[49m\u001b[43mfunctions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexec_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43mquestion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquestion\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[29], line 76\u001b[0m, in \u001b[0;36mcode_exe\u001b[0;34m(prepare, type, functions, question)\u001b[0m\n\u001b[1;32m     74\u001b[0m     code_interpreter\u001b[38;5;241m.\u001b[39mexecute_code(model1)\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 76\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mconvert_str_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     77\u001b[0m     code_interpreter\u001b[38;5;241m.\u001b[39mexecute_code(model)\n\u001b[1;32m     78\u001b[0m     code_interpreter\u001b[38;5;241m.\u001b[39mexecute_code(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprint(result)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/A-Projects/Graduation/embedding/opencode/utils/utils1.py:81\u001b[0m, in \u001b[0;36mconvert_str_function\u001b[0;34m(json_str)\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mconvert_str_function\u001b[39m(json_str):\n\u001b[0;32m---> 81\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mast\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mliteral_eval\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjson_str\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     82\u001b[0m     results \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     83\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m data:\n",
      "File \u001b[0;32m~/anaconda3/envs/base1/lib/python3.10/ast.py:108\u001b[0m, in \u001b[0;36mliteral_eval\u001b[0;34m(node_or_string)\u001b[0m\n\u001b[1;32m    106\u001b[0m                 \u001b[38;5;28;01mreturn\u001b[39;00m left \u001b[38;5;241m-\u001b[39m right\n\u001b[1;32m    107\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _convert_signed_num(node)\n\u001b[0;32m--> 108\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_convert\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode_or_string\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/base1/lib/python3.10/ast.py:88\u001b[0m, in \u001b[0;36mliteral_eval.<locals>._convert\u001b[0;34m(node)\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(\u001b[38;5;28mmap\u001b[39m(_convert, node\u001b[38;5;241m.\u001b[39melts))\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(node, List):\n\u001b[0;32m---> 88\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m_convert\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43melts\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(node, Set):\n\u001b[1;32m     90\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mset\u001b[39m(\u001b[38;5;28mmap\u001b[39m(_convert, node\u001b[38;5;241m.\u001b[39melts))\n",
      "File \u001b[0;32m~/anaconda3/envs/base1/lib/python3.10/ast.py:97\u001b[0m, in \u001b[0;36mliteral_eval.<locals>._convert\u001b[0;34m(node)\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(node\u001b[38;5;241m.\u001b[39mkeys) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(node\u001b[38;5;241m.\u001b[39mvalues):\n\u001b[1;32m     96\u001b[0m         _raise_malformed_node(node)\n\u001b[0;32m---> 97\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m_convert\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeys\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     98\u001b[0m \u001b[43m                    \u001b[49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m_convert\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(node, BinOp) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(node\u001b[38;5;241m.\u001b[39mop, (Add, Sub)):\n\u001b[1;32m    100\u001b[0m     left \u001b[38;5;241m=\u001b[39m _convert_signed_num(node\u001b[38;5;241m.\u001b[39mleft)\n",
      "File \u001b[0;32m~/anaconda3/envs/base1/lib/python3.10/ast.py:97\u001b[0m, in \u001b[0;36mliteral_eval.<locals>._convert\u001b[0;34m(node)\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(node\u001b[38;5;241m.\u001b[39mkeys) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(node\u001b[38;5;241m.\u001b[39mvalues):\n\u001b[1;32m     96\u001b[0m         _raise_malformed_node(node)\n\u001b[0;32m---> 97\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m_convert\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeys\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     98\u001b[0m \u001b[43m                    \u001b[49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m_convert\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(node, BinOp) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(node\u001b[38;5;241m.\u001b[39mop, (Add, Sub)):\n\u001b[1;32m    100\u001b[0m     left \u001b[38;5;241m=\u001b[39m _convert_signed_num(node\u001b[38;5;241m.\u001b[39mleft)\n",
      "File \u001b[0;32m~/anaconda3/envs/base1/lib/python3.10/ast.py:107\u001b[0m, in \u001b[0;36mliteral_eval.<locals>._convert\u001b[0;34m(node)\u001b[0m\n\u001b[1;32m    105\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    106\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m left \u001b[38;5;241m-\u001b[39m right\n\u001b[0;32m--> 107\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_convert_signed_num\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/base1/lib/python3.10/ast.py:81\u001b[0m, in \u001b[0;36mliteral_eval.<locals>._convert_signed_num\u001b[0;34m(node)\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     80\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m-\u001b[39m operand\n\u001b[0;32m---> 81\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_convert_num\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/base1/lib/python3.10/ast.py:72\u001b[0m, in \u001b[0;36mliteral_eval.<locals>._convert_num\u001b[0;34m(node)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_convert_num\u001b[39m(node):\n\u001b[1;32m     71\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(node, Constant) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(node\u001b[38;5;241m.\u001b[39mvalue) \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mcomplex\u001b[39m):\n\u001b[0;32m---> 72\u001b[0m         \u001b[43m_raise_malformed_node\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     73\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m node\u001b[38;5;241m.\u001b[39mvalue\n",
      "File \u001b[0;32m~/anaconda3/envs/base1/lib/python3.10/ast.py:69\u001b[0m, in \u001b[0;36mliteral_eval.<locals>._raise_malformed_node\u001b[0;34m(node)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m lno \u001b[38;5;241m:=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(node, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlineno\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m     68\u001b[0m     msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m on line \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlno\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m---> 69\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg \u001b[38;5;241m+\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnode\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: malformed node or string on line 1: <ast.BinOp object at 0x7f76d8167880>"
     ]
    }
   ],
   "source": [
    "from planner.tools import get_pla_user\n",
    "from planner.prompt import get_planer\n",
    "from utils.api import gpt_chat\n",
    "from utils.utils1 import read_file,write_file,extract_functions,convert_str_function\n",
    "import os\n",
    "from planner.tools import get_plan\n",
    "from utils.rag import ChoromaDBManager\n",
    "from developer.prompt import get_developer\n",
    "from developer.tools import get_dev_user\n",
    "from utils.notebook_serializer import NotebookSerializer\n",
    "from utils.local_interpreter import LocalCodeInterpreter\n",
    "import sys\n",
    "import json\n",
    "import importlib\n",
    "import re\n",
    "\n",
    "def func_preprocess(functions):\n",
    "    func_call = convert_str_function(functions[0])\n",
    "    data_processed = func_call.split(\"\\n\")\n",
    "    updated_lines = []\n",
    "\n",
    "    train = 0\n",
    "    test = 0\n",
    "\n",
    "    for tmp in data_processed:\n",
    "        if 'data=\"train_data\"' in tmp:\n",
    "            if train == 0:\n",
    "                data_name = 'train_data'\n",
    "            else:\n",
    "                data_name = f'train_data{train}'\n",
    "            output_var = f'train_data{train + 1}'\n",
    "            tmp = tmp.replace('data=\"train_data\"', f'data={data_name}')\n",
    "            tmp = re.sub(r'^result\\s*=', f'{output_var} =', tmp)\n",
    "            train += 1\n",
    "        elif 'data=\"test_data\"' in tmp:\n",
    "            if test == 0:\n",
    "                data_name = 'test_data'\n",
    "            else:\n",
    "                data_name = f'test_data{test}'\n",
    "            output_var = f'test_data{test + 1}'\n",
    "            tmp = tmp.replace('data=\"test_data\"', f'data={data_name}')\n",
    "            tmp = re.sub(r'^result\\s*=', f'{output_var} =', tmp)\n",
    "            test += 1\n",
    "        updated_lines.append(tmp)\n",
    "    return updated_lines,train,test\n",
    "\n",
    "def code_exe(prepare,type,functions,question):\n",
    "    notebook = NotebookSerializer(\"./\")\n",
    "    code_interpreter = LocalCodeInterpreter(work_dir=\"./\",notebook_serializer=notebook,task_id=\"111\")\n",
    "    code_interpreter.initialize()\n",
    "\n",
    "    for func in prepare:\n",
    "        file = set()\n",
    "        if func[\"source_file\"] not in file:\n",
    "            module_name = f\"tool_code.{func['source_file'].replace('.md', '')}\"\n",
    "            module = importlib.import_module(module_name)\n",
    "            header = module.get_header()\n",
    "            tool = f\"from tool_code.{func['source_file'].replace('.md', '')} import {func['tool_name']}\"\n",
    "            code_interpreter.execute_code(header)\n",
    "            code_interpreter.execute_code(tool)\n",
    "            file.add(func['source_file'])\n",
    "    if (len(functions) > 1) and (type in [\"pre\",\"eval\"]):\n",
    "        update_func,train_index,test_index = func_preprocess(functions)\n",
    "        data_load =\"\"\"train_data = pd.read_csv(\"{train_path}\")\n",
    "        test_data = pd.read_csv(\"{test_path}\")\"\"\"\n",
    "        path1 = os.path.join(os.path.dirname(question),\"train.csv\")\n",
    "        path2 = os.path.join(os.path.dirname(question),\"test.csv\")\n",
    "        data_load=data_load.format(train_path=path1,test_path=path2)\n",
    "        code_interpreter.execute_code(data_load)\n",
    "        for i in update_func:\n",
    "            code_interpreter.execute_code(i)\n",
    "        model = convert_str_function(functions[1])\n",
    "        model1=model.replace('\"train_data\"', f'train_data{train_index}').replace('\"test_data\"', f'test_data{test_index}')\n",
    "        code_interpreter.execute_code(model1)\n",
    "    else:\n",
    "        model = convert_str_function(functions[0])\n",
    "        code_interpreter.execute_code(model)\n",
    "        code_interpreter.execute_code(\"print(result)\")\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    type1=\"opt\"\n",
    "    question=\"./test_case/o4/question.txt\"\n",
    "    agent =\"deepseek\"\n",
    "    # planner环节\n",
    "    print(\"planner start\")\n",
    "    planer = get_planer(problem_type=type1)\n",
    "    info = get_pla_user(ques=question,problem_type=type1)\n",
    "    # response1 = gpt_chat(sys=planer,user=info,provider=\"deepseek\")\n",
    "    # write_file(os.path.join(os.path.dirname(question),f\"plan_{agent}.txt\"), response1)\n",
    "    response1 = read_file(os.path.join(os.path.dirname(question),f\"plan_{agent}.txt\"))\n",
    "\n",
    "    # RAG环节\n",
    "    print(\"RAG start\")\n",
    "    chroma_db = ChoromaDBManager(os.path.join(os.path.dirname(question), \"tool_db\"))\n",
    "    chroma_db.store_tools_to_db(dir_path=\"./tool_doc_md\")\n",
    "    plan = get_plan(str_path=os.path.join(os.path.dirname(question),f\"plan_{agent}.txt\"))\n",
    "    prepare_funcs=chroma_db.get_all_tools(plan)\n",
    "\n",
    "    #developer环节\n",
    "    print(\"developer start\")\n",
    "    devloper_prompt = get_developer(problem_type=type1,func=prepare_funcs)\n",
    "    user2 = get_dev_user(question=question,problem_type=type1)\n",
    "    # response2 = gpt_chat(sys=devloper_prompt,user=user2)\n",
    "    # write_file(os.path.join(os.path.dirname(question),f\"dev_{agent}.txt\"), response2)\n",
    "    response2 = read_file(os.path.join(os.path.dirname(question),f\"dev_{agent}.txt\"))\n",
    "\n",
    "    # 代码执行环节\n",
    "    print(\"code execute start\")\n",
    "    exec_func = extract_functions(os.path.join(os.path.dirname(question),f\"dev_{agent}.txt\"))\n",
    "    code_exe(prepare=prepare_funcs,type=type1,functions=exec_func,question=question)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
